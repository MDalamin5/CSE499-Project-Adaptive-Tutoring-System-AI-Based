{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement From structured  Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_response = \"pass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableBranch, RunnableSequence\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model=ChatGroq(groq_api_key=groq_api_key,model_name=\"qwen-2.5-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StuOutputCorrectness(BaseModel):\n",
    "    sentiment: Literal['correct', 'partially_correct', 'incorrect'] = Field(description='Give the sentiment from the student response')\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=StuOutputCorrectness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a tutor analyzing a student's attempt to solve a math problem.  The student's response is provided below.\n",
    "\n",
    "Student Response: {response}\n",
    "\n",
    "Based *solely* on the student's response, classify their answer as either: 'correct', 'partially_correct', or 'incorrect'.\n",
    "\n",
    "{format_instruction}\n",
    "\n",
    "*Important:* Provide *only* the JSON output specified in the format instructions. Do not include any other text.\n",
    "\"\"\",\n",
    "    input_variables=['response'],\n",
    "    partial_variables={\n",
    "        'format_instruction': parser.get_format_instructions()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuOutputCorrectness(sentiment='incorrect')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = classifier_chain.invoke(\n",
    "    {\n",
    "        'response': \"The sum of 2+2=5.0\"\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'incorrect'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "      +----------+       \n",
      "      | ChatGroq |       \n",
      "      +----------+       \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| StuOutputCorrectness | \n",
      "+----------------------+ \n"
     ]
    }
   ],
   "source": [
    "classifier_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Build Conditional Branch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_correct = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an AI tutor designing a prompt for a system to generate a response for a student. The student has correctly responded with: {response}. The original problem is: What is 2+2?.\n",
    "\n",
    "Craft an adaptive prompt that will guide the system to:\n",
    "\n",
    "1.  Briefly acknowledge the student's correct response and provide positive reinforcement (e.g., \"Excellent!\", \"Correct!\", \"Great job!\").\n",
    "2.  Prompt the system to offer a concise question that leads the student to the next logical step in solving the original problem. The question should not give away the answer but encourage the student to apply their knowledge.\n",
    "\n",
    "Example Adaptive Prompt:\n",
    "\"The student has correctly identified [previous step]. Now, prompt the student to explain how they would use this information to solve for [next unknown variable] in the original equation. Focus on eliciting the student's reasoning.\"\n",
    "\"\"\",\n",
    "    input_variables=['response']\n",
    ")\n",
    "\n",
    "prompt_partially_correct = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an AI tutor designing a prompt for a system to generate a response for a student. The student's response, {response}, to the problem, what is 2+2?, is partially correct.\n",
    "\n",
    "Craft an adaptive prompt that will guide the system to:\n",
    "\n",
    "1.  Instruct the system to acknowledge that the student is on the right track but has made a specific error.\n",
    "2.  Prompt the system to provide a hint or question that directly addresses the error, focusing on the underlying concept or calculation that was incorrect.\n",
    "3.  Encourage the system to guide the student to revise their answer based on the hint.\n",
    "\n",
    "Example Adaptive Prompt:\n",
    "\"The student has correctly applied [concept], but they made an error in [specific calculation]. Prompt the system to ask the student to double-check their work in that area and explain why [correct approach] is necessary. Guide the student to identify the correct result.\"\n",
    "\"\"\",\n",
    "    input_variables=['response']\n",
    ")\n",
    "\n",
    "prompt_incorrect = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an AI tutor designing a prompt for a system to generate a response for a student. The student's response, {response}, to the problem, what is 2+2?, is incorrect.\n",
    "\n",
    "Craft an adaptive prompt that will guide the system to:\n",
    "\n",
    "1.  Instruct the system to avoid directly stating that the answer is wrong. Instead, prompt it to use language that gently suggests a need for review or a different approach.\n",
    "2.  Prompt the system to offer a general hint or probing question that targets a fundamental concept related to the problem. This hint should help the student identify their misconception or gap in understanding.\n",
    "3.  Guide the system to encourage the student to rethink the problem from a different perspective.\n",
    "\n",
    "Example Adaptive Prompt:\n",
    "\"The student's response suggests a misunderstanding of [fundamental concept]. Prompt the system to ask the student to explain the principles of [fundamental concept] in their own words and how they relate to the given problem. Guide them to identify a more appropriate strategy for solving the problem.\"\n",
    "\"\"\",\n",
    "    input_variables=['response']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: x.sentiment == 'correct', prompt_correct | model | str_parser),\n",
    "    (lambda x: x.sentiment == 'partially_correct', prompt_partially_correct | model | str_parser),\n",
    "    (lambda x: x.sentiment == 'incorrect', prompt_incorrect | model | str_parser),\n",
    "    RunnableLambda(lambda x: \"Could find any kind of sentiment.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_prompt = final_chain.invoke(\n",
    "    {\n",
    "        'response': \"the sum of 2+2=5\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Prompt:\n",
      "\"The student's response indicates a potential gap in understanding basic arithmetic. Prompt the system to guide the student by asking them to recount the process they used to arrive at their answer. Encourage the system to ask the student to consider the concept of addition as the combining of quantities and to reflect on what it means to add two numbers together. Guide the system to suggest the student to visualize the problem using objects or drawings to see the addition of 2 and 2 in a concrete way.\"\n"
     ]
    }
   ],
   "source": [
    "print(adaptive_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_prompt = final_chain.invoke(\n",
    "    {\n",
    "        'response': \"the sum of 2+2=4\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great job! Now, let's think about how you can express the result of 2+2 in different ways, such as using objects or drawings. How might you do that?\n"
     ]
    }
   ],
   "source": [
    "print(adaptive_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "      +----------+       \n",
      "      | ChatGroq |       \n",
      "      +----------+       \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *****Access Gemma3:1B*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"gemma3:1b\")  # Replace \"llama3\" with your model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi there! How's your day going so far? ðŸ˜Š \\n\\nIs there anything youâ€™d like to talk about or need help with?\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOllama(model=\"gemma3:1b\") # Replace \"llama3\" with your model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I help you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"hi sir\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableBranch, RunnableSequence\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model=ChatGroq(groq_api_key=groq_api_key,model_name=\"qwen-2.5-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StuOutputCorrectness(BaseModel):\n",
    "    sentiment: Literal['correct', 'partially_correct', 'incorrect'] = Field(description='Give the sentiment from the student response')\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=StuOutputCorrectness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Analyze the following student response and classify its correctness. \"\n",
    "        \"Determine whether it is 'correct', 'partially_correct', or 'incorrect'.\\n\\n\"\n",
    "        \"Student Response: {response}\\n\\n\"\n",
    "        \"Provide the classification following this format:\\n{format_instruction}\"\n",
    "    ),\n",
    "    input_variables=['response'],\n",
    "    partial_variables={\n",
    "        'format_instruction': parser.get_format_instructions()\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_correct = PromptTemplate(\n",
    "    template=(\n",
    "        \"The student provided a correct response: {response}.\\n\\n\"\n",
    "        \"Generate a focused and concise adaptive prompt to guide the student to the next step \"\n",
    "        \"without unnecessary repetition. The adaptive prompt should ensure that the model only provides \"\n",
    "        \"the best next-step guidance in solving the problem.\"\n",
    "    ),\n",
    "    input_variables=['response']\n",
    ")\n",
    "\n",
    "prompt_partially_correct = PromptTemplate(\n",
    "    template=(\n",
    "        \"The student's response is partially correct: {response}.\\n\\n\"\n",
    "        \"Identify the specific mistake or misunderstanding in the response and provide constructive feedback. \"\n",
    "        \"Offer guidance that helps the student recognize their mistake and encourage them to refine their answer. \"\n",
    "        \"Additionally, include a strategic hint or ask the student: 'Would you like more hints?' to ensure engagement.\\n\\n\"\n",
    "        \"Now, generate the best adaptive prompt so the model can provide the most effective response for the next step.\"\n",
    "    ),\n",
    "    input_variables=['response']\n",
    ")\n",
    "\n",
    "prompt_incorrect = PromptTemplate(\n",
    "    template=(\n",
    "        \"The student's response is incorrect: {response}.\\n\\n\"\n",
    "        \"Analyze why the student may have made this mistake. Did they misunderstand the concept? \"\n",
    "        \"Did they miscalculate? Provide targeted clarification based on the likely issue. \"\n",
    "        \"Offer a step-by-step hint that gradually leads them toward the correct answer.\\n\\n\"\n",
    "        \"Now, generate the only one best adaptive prompt that ensures the model provides an effective response to help the student progress.\"\n",
    "    ),\n",
    "    input_variables=['response']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: x.sentiment == 'correct', prompt_correct | model | str_parser),\n",
    "    (lambda x: x.sentiment == 'partially_correct', prompt_partially_correct | model | str_parser),\n",
    "    (lambda x: x.sentiment == 'incorrect', prompt_incorrect | model | str_parser),\n",
    "    RunnableLambda(lambda x: \"Could find any kind of sentiment.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_prompt = final_chain.invoke(\n",
    "    {\n",
    "        'response': \"the sum of 2+2=5\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an adaptive prompt that ensures the model provides an effective response to help the student progress, we need to focus on what information is missing or misunderstood by the student. Since the specific context of the student's mistake is not provided, I'll design a prompt that can be broadly applied to various learning scenarios where a student has answered incorrectly due to a possible misunderstanding or miscalculation.\n",
      "\n",
      "Adaptive Prompt:\n",
      "\"First, let's identify where the misunderstanding or miscalculation occurred. Can you walk through the steps you took to reach your answer? Once we pinpoint the exact step where things went awry, I'll provide a targeted explanation or clarification. This will help you understand the concept more clearly and avoid similar mistakes in the future. Remember, the goal is to learn from this, not to just get the right answer. Let's break it down together.\"\n",
      "\n",
      "This prompt is designed to engage the student in self-reflection and to identify the root cause of their mistake. It encourages a step-by-step analysis of their thought process, which can help in pinpointing the exact issue, whether it's a conceptual misunderstanding or a simple miscalculation.\n"
     ]
    }
   ],
   "source": [
    "print(adaptive_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

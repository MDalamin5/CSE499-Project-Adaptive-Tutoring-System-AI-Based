{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\torchGPU\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'TranslationResult' has no attribute 'model_json_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Get format instructions from the output parser\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m format_instructions \u001b[38;5;241m=\u001b[39m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_format_instructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Chain\u001b[39;00m\n\u001b[0;32m     49\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m output_parser\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\torchGPU\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:92\u001b[0m, in \u001b[0;36mPydanticOutputParser.get_format_instructions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the format instructions for the JSON output.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    The format instructions for the JSON output.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Copy schema to avoid altering original Pydantic schema.\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_json_schema\u001b[49m()\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Remove extraneous fields.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m reduced_schema \u001b[38;5;241m=\u001b[39m schema\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'TranslationResult' has no attribute 'model_json_schema'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import re\n",
    "\n",
    "# Load your Groq API Key from environment variables\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")  # IMPORTANT: Set this in your environment\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"Groq API key not found.  Please set the GROQ_API_KEY environment variable.\")\n",
    "\n",
    "# Initialize Groq model\n",
    "model = ChatGroq(model_name=\"qwen-2.5-32b\", groq_api_key=groq_api_key)\n",
    "\n",
    "\n",
    "# Define the Pydantic model for structured output\n",
    "class TranslationResult(BaseModel):\n",
    "    bangla_translation: str = Field(description=\"The Bangla translation of the input text. Do not translate any text enclosed in <<...>> or any line starting with ####. Also, do NOT translate any numbers; keep them in their original English numeral form. Mathematical expressions/answers must remain in their original form.\")\n",
    "\n",
    "\n",
    "# Create a PydanticOutputParser\n",
    "output_parser = PydanticOutputParser(pydantic_object=TranslationResult)\n",
    "\n",
    "# Create the prompt\n",
    "template = \"\"\"You are a highly precise and professional language translator assistant. Your ONLY task is to translate English language text to Bangla language. You are given ONE piece of text as input, and you MUST return ONLY the Bangla translation of that text in the following JSON format:\n",
    "\n",
    "{{\n",
    "    \"bangla_translation\": \"The Bangla translation\"\n",
    "}}\n",
    "\n",
    "Do not add any introductory or concluding phrases, questions, or conversational elements. Do not translate any text enclosed in <<...>> or any line starting with ####. Also, do NOT translate any numbers; keep them in their original English numeral form. Mathematical expressions/answers must remain in their original form.\n",
    "\n",
    "Here is the text to translate:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Get format instructions from the output parser\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Chain\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    \"\"\"Translates English text to Bangla using structured output.\"\"\"\n",
    "    try:\n",
    "        result = chain.invoke({\"text\": text, \"format_instructions\": format_instructions})\n",
    "        return result.bangla_translation  # Access the translated text from the object\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_gsm8k(file_path):\n",
    "    \"\"\"\n",
    "    Loads the GSM8k JSON file, translates questions and answers,\n",
    "    and saves the translated data back to a new JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:  # Specify encoding!\n",
    "        data = json.load(f)\n",
    "\n",
    "    translated_data = []\n",
    "    for item in data:\n",
    "        question_en = item[\"question\"]\n",
    "        answer_en = item[\"answer\"]\n",
    "\n",
    "        # Translate Question\n",
    "        question_bn = translate_text(question_en)\n",
    "\n",
    "        # Translate Answer (preserving calculations)\n",
    "        def replace_with_original(match):\n",
    "            return match.group(0)  # Return the original matched text\n",
    "\n",
    "        # Split the answer into translatable and non-translatable parts.\n",
    "        parts = re.split(r'(<<.*?>>|####.*)', answer_en)  # Split by <<...>> and ####...\n",
    "        translated_parts = []\n",
    "\n",
    "        for i, part in enumerate(parts):\n",
    "            if re.match(r'(<<.*?>>|####.*)', part):  # Check if it's a calculation part\n",
    "                translated_parts.append(part)  # Keep the calculation part as is\n",
    "            else:\n",
    "                translated_part = translate_text(part)\n",
    "                translated_parts.append(translated_part if translated_part else part)  # Translate or keep original if translation fails\n",
    "\n",
    "        answer_bn = \"\".join(translated_parts)  # Reassemble the translated answer.\n",
    "\n",
    "        translated_data_item = {\n",
    "            \"question_en\": question_en,\n",
    "            \"answer_en\": answer_en,\n",
    "            \"question_bn\": question_bn,\n",
    "            \"answer_bn\": answer_bn\n",
    "        }\n",
    "        translated_data.append(translated_data_item)\n",
    "\n",
    "\n",
    "    # Save the translated data to a new JSON file\n",
    "    output_file_path = \"gsm8k_bn-structured.json\"\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(translated_data, outfile, indent=4, ensure_ascii=False)  # ensure_ascii=False for Bangla characters\n",
    "\n",
    "    print(f\"Translation complete. Translated data saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"gsm8k.json\"  # Replace with the actual path to your file\n",
    "process_gsm8k(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

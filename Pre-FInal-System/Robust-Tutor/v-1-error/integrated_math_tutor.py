import streamlit as st
import os
import re
import json
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import PydanticOutputParser
from langchain.schema.runnable import RunnableLambda
from pydantic import BaseModel, Field
from typing import Literal, Dict, Any, List
import time

# Load environment variables
load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY")

# Check if API key is available
if not groq_api_key:
    st.error("Groq API key not found. Please configure it in the setup page.")
    st.stop()

# Define Pydantic models for structured output parsing
class StuOutputCorrectness(BaseModel):
    sentiment: Literal['correct', 'partially_correct', 'incorrect'] = Field(
        description='The sentiment classification of the student response'
    )

class AdaptivePrompt(BaseModel):
    adaptive_prompt: str = Field(
        description="The final adaptive prompt to guide the main model."
    )

class TutorResponse(BaseModel):
    hint: str = Field(
        description="The hint or guidance for the student (without giving away the solution)"
    )
    reasoning: str = Field(
        description="The reasoning or thought process behind the hint"
    )

class StepSolution(BaseModel):
    step_explanation: str = Field(
        description="The explanation of the current step in solving the problem"
    )
    understanding_check: str = Field(
        description="A question to check if the student understands this step"
    )
    is_final_step: bool = Field(
        description="Whether this is the final step in solving the problem"
    )
    next_hint: str = Field(
        description="A hint about what the next step would be (if not final step)"
    )

# Custom output parser with robust JSON extraction
class RobustOutputParser:
    def __init__(self, pydantic_parser):
        self.pydantic_parser = pydantic_parser
        self.model_class = pydantic_parser.pydantic_object
    
    def parse(self, text):
        # Try to extract JSON from the text using regex
        json_match = re.search(r'({.*})', text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
            try:
                # Try to parse the extracted JSON
                parsed_json = json.loads(json_str)
                # Create an instance of the Pydantic model
                return self.model_class(**parsed_json)
            except json.JSONDecodeError:
                # If JSON parsing fails, try to clean up the JSON string
                cleaned_json = self._clean_json_string(json_str)
                try:
                    parsed_json = json.loads(cleaned_json)
                    return self.model_class(**parsed_json)
                except:
                    # If all parsing attempts fail, create a default instance
                    return self._create_default_instance()
        else:
            # If no JSON-like structure is found, try to extract information from the text
            try:
                # For non-JSON responses, try to intelligently extract the parts
                if self.model_class == StepSolution:
                    return self._extract_step_solution(text)
                else:
                    return self._create_default_instance()
            except:
                # If all extraction attempts fail, create a default instance
                return self._create_default_instance()
    
    def _clean_json_string(self, json_str):
        # Remove any thinking tags
        json_str = re.sub(r'<think>.*?</think>', '', json_str, flags=re.DOTALL)
        # Remove any non-JSON text before the first {
        json_str = re.sub(r'^[^{]*', '', json_str)
        # Remove any non-JSON text after the last }
        json_str = re.sub(r'}[^}]*$', '}', json_str)
        return json_str
    
    def _create_default_instance(self):
        if self.model_class == AdaptivePrompt:
            return AdaptivePrompt(adaptive_prompt="The model output could not be parsed correctly. Please provide a hint for the current step without giving away the solution.")
        elif self.model_class == StuOutputCorrectness:
            return StuOutputCorrectness(sentiment="partially_correct")
        elif self.model_class == TutorResponse:
            return TutorResponse(
                hint="I need to provide a hint rather than a complete solution. What specific technique could you apply here?",
                reasoning="The parsing failed, but I should focus on providing guidance without solutions."
            )
        elif self.model_class == StepSolution:
            return StepSolution(
                step_explanation="I'll help you solve this step by step. Let's start by understanding the problem.",
                understanding_check="Do you understand how we should approach this problem?",
                is_final_step=False,
                next_hint="We'll need to identify the key mathematical concepts involved."
            )
    
    def _extract_step_solution(self, text):
        paragraphs = text.split('\n\n')
        explanation = paragraphs[0] if paragraphs else text
        check = "Do you understand this step?" 
        for p in paragraphs:
            if "?" in p and any(word in p.lower() for word in ["understand", "sense", "follow", "clear"]):
                check = p
                break
        
        is_final = "final" in text.lower() or "answer" in text.lower() or "solution" in text.lower()
        next_hint = ""
        for p in paragraphs:
            if "next" in p.lower() and not is_final:
                next_hint = p
                break
        
        return StepSolution(
            step_explanation=explanation,
            understanding_check=check,
            is_final_step=is_final,
            next_hint=next_hint if not is_final else ""
        )

# Initialize parsers
sentiment_parser = PydanticOutputParser(pydantic_object=StuOutputCorrectness)
adaptive_parser = PydanticOutputParser(pydantic_object=AdaptivePrompt)
tutor_response_parser = PydanticOutputParser(pydantic_object=TutorResponse)
step_solution_parser = PydanticOutputParser(pydantic_object=StepSolution)

# Create robust parsers
robust_sentiment_parser = RobustOutputParser(sentiment_parser)
robust_adaptive_parser = RobustOutputParser(adaptive_parser)
robust_tutor_response_parser = RobustOutputParser(tutor_response_parser)
robust_step_solution_parser = RobustOutputParser(step_solution_parser)

# Define system prompts for both modes and languages
# Adaptive Mode - English
ADAPTIVE_PROMPT_ENGLISH = """
You are an AI math tutor specializing in high school algebra. Your goal is to guide students towards understanding and solving math problems independently by providing helpful hints and targeted questions.
    
CRITICAL INSTRUCTION: NEVER PROVIDE COMPLETE SOLUTIONS. You must only give hints and guiding questions.
    
Your Step-by-Step Approach:
1. When the student presents a math problem:
   - Identify the core concepts involved
   - Provide ONLY ONE small hint about the first step
   - Ask a specific guiding question to help them think through this step
   - STOP and wait for their response
    
2. When the student responds to your hint:
   - If correct: Acknowledge their success and provide a hint for the NEXT step only
   - If partially correct: Clarify their misunderstanding and provide a more targeted hint for the SAME step
   - If incorrect: Provide a more basic hint for the SAME step and ask a simpler guiding question
    
3. Continue this process for each step of the problem
    
IMPORTANT RULES:
- NEVER solve more than one step at a time
- NEVER provide formulas or procedures that directly solve the problem
- NEVER give away answers, even if the student is struggling
- NEVER proceed to the next step until the student has correctly completed the current step
- ALWAYS phrase hints as questions or suggestions, not direct instructions
- ALWAYS ask a specific guiding question after each hint
- ALWAYS keep responses focused and concise
    
Example of CORRECT approach:
Student: "Solve x^2 + 5x + 6 = 0"
You: "This is a quadratic equation. Do you remember what method we can use to solve quadratics? Can you try to factor this expression?"
    
Example of INCORRECT approach (DO NOT DO THIS):
Student: "Solve x^2 + 5x + 6 = 0"
You: "To solve this quadratic equation, we can factor it as (x+2)(x+3)=0, which gives us x=-2 or x=-3."
    
Remember: Your goal is to help students develop problem-solving skills, not to solve problems for them.
    
RESPONSE FORMAT:
You must structure your response as a JSON object with two fields:
1. "hint": The actual hint or guidance you want to provide to the student
2. "reasoning": Your internal reasoning about why you chose this hint and what you're trying to accomplish
    
Example response format:
{
    "hint": "This is a quadratic equation. Do you remember what method we can use to solve quadratics? Can you try to factor this expression?",
    "reasoning": "I identified this as a quadratic equation that can be solved by factoring. I want to guide the student to recognize this approach without giving away the factors. If they can identify that factoring is appropriate, they can try to find the factors of 6 that sum to 5."
}
"""

# Adaptive Mode - Bangla
ADAPTIVE_PROMPT_BANGLA = """
‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶è‡¶Ü‡¶á ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï, ‡¶Ø‡¶ø‡¶®‡¶ø ‡¶â‡¶ö‡ßç‡¶ö ‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º‡ßá‡¶∞ ‡¶¨‡ßÄ‡¶ú‡¶ó‡¶£‡¶ø‡¶§ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø ‡¶π‡¶≤ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶∏‡ßç‡¶¨‡¶æ‡¶ß‡ßÄ‡¶®‡¶≠‡¶æ‡¶¨‡ßá ‡¶ó‡¶æ‡¶£‡¶ø‡¶§‡¶ø‡¶ï ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ ‡¶ï‡¶∞‡¶æ, ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßá‡•§

‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ: ‡¶ï‡¶ñ‡¶®‡¶á ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§

‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø:
1. ‡¶Ø‡¶ñ‡¶® ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ó‡¶æ‡¶£‡¶ø‡¶§‡¶ø‡¶ï ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶® ‡¶ï‡¶∞‡ßá:
   - ‡¶∏‡¶Æ‡ßç‡¶™‡ßÉ‡¶ï‡ßç‡¶§ ‡¶Æ‡ßÇ‡¶≤ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®
   - ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶õ‡ßã‡¶ü ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
   - ‡¶è‡¶á ‡¶ß‡¶æ‡¶™‡¶ü‡¶ø ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
   - ‡¶•‡¶æ‡¶Æ‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®

2. ‡¶Ø‡¶ñ‡¶® ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ú‡¶æ‡¶®‡¶æ‡¶Ø‡¶º:
   - ‡¶Ø‡¶¶‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï ‡¶π‡¶Ø‡¶º: ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶æ‡¶´‡¶≤‡ßç‡¶Ø ‡¶∏‡ßç‡¶¨‡ßÄ‡¶ï‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
   - ‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶Ç‡¶∂‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶†‡¶ø‡¶ï ‡¶π‡¶Ø‡¶º: ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡ßã‡¶ù‡¶æ‡¶¨‡ßÅ‡¶ù‡¶ø ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶è‡¶ï‡¶á ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∞‡¶ì ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
   - ‡¶Ø‡¶¶‡¶ø ‡¶≠‡ßÅ‡¶≤ ‡¶π‡¶Ø‡¶º: ‡¶è‡¶ï‡¶á ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∞‡¶ì ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶π‡¶ú ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®

3. ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶á ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ö‡¶æ‡¶≤‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶®

‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶ø‡¶Ø‡¶º‡¶Æ:
- ‡¶ï‡¶ñ‡¶®‡¶ì ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞‡ßá ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶ß‡¶æ‡¶™ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ
- ‡¶ï‡¶ñ‡¶®‡¶ì ‡¶è‡¶Æ‡¶® ‡¶∏‡ßÇ‡¶§‡ßç‡¶∞ ‡¶¨‡¶æ ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ ‡¶Ø‡¶æ ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßá
- ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ ‡¶ï‡¶∞‡¶≤‡ßá‡¶ì ‡¶ï‡¶ñ‡¶®‡¶ì ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶¨‡ßá‡¶® ‡¶®‡¶æ
- ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶ß‡¶æ‡¶™‡¶ü‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶®‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ï‡¶ñ‡¶®‡¶ì ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Ø‡¶æ‡¶¨‡ßá‡¶® ‡¶®‡¶æ
- ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§‡¶ó‡ßÅ‡¶≤‡¶ø‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶¨‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá ‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®, ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá ‡¶®‡¶Ø‡¶º
- ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§‡ßá‡¶∞ ‡¶™‡¶∞‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞‡ßÄ‡¶≠‡ßÇ‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®

‡¶∏‡¶†‡¶ø‡¶ï ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø‡¶∞ ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:
‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ: "x^2 + 5x + 6 = 0 ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®"
‡¶Ü‡¶™‡¶®‡¶ø: "‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¶‡ßç‡¶¨‡¶ø‡¶ò‡¶æ‡¶§ ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Æ‡¶®‡ßá ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶ï‡ßã‡¶® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßç‡¶¨‡¶ø‡¶ò‡¶æ‡¶§ ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø? ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶è‡¶á ‡¶Ö‡¶≠‡¶ø‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶ü‡¶ø ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®?"

‡¶≠‡ßÅ‡¶≤ ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø‡¶∞ ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ (‡¶è‡¶ü‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ):
‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ: "x^2 + 5x + 6 = 0 ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®"
‡¶Ü‡¶™‡¶®‡¶ø: "‡¶è‡¶á ‡¶¶‡ßç‡¶¨‡¶ø‡¶ò‡¶æ‡¶§ ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£‡¶ü‡¶ø ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá, ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶è‡¶ü‡¶ø‡¶ï‡ßá (x+2)(x+3)=0 ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø, ‡¶Ø‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ x=-2 ‡¶¨‡¶æ x=-3 ‡¶¶‡ßá‡¶Ø‡¶º‡•§"

‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶®: ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø ‡¶π‡¶≤ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶¶‡¶ï‡ßç‡¶∑‡¶§‡¶æ ‡¶¨‡¶ø‡¶ï‡¶æ‡¶∂‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶æ, ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ ‡¶®‡¶Ø‡¶º‡•§

‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü:
‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ï‡ßá ‡¶¶‡ßÅ‡¶ü‡¶ø ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞ ‡¶∏‡¶π ‡¶è‡¶ï‡¶ü‡¶ø JSON ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá ‡¶ï‡¶æ‡¶†‡¶æ‡¶Æ‡ßã‡¶¨‡¶¶‡ßç‡¶ß ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá:
1. "hint": ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶® ‡¶è‡¶Æ‡¶® ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶¨‡¶æ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ
2. "reasoning": ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßá‡¶® ‡¶è‡¶á ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§‡¶ü‡¶ø ‡¶¨‡ßá‡¶õ‡ßá ‡¶®‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡¶® ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßÄ ‡¶Ö‡¶∞‡ßç‡¶ú‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡¶õ‡ßá‡¶® ‡¶∏‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶Ö‡¶≠‡ßç‡¶Ø‡¶®‡ßç‡¶§‡¶∞‡ßÄ‡¶£ ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø

‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡ßá‡¶∞ ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:
{
    "hint": "‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¶‡ßç‡¶¨‡¶ø‡¶ò‡¶æ‡¶§ ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Æ‡¶®‡ßá ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶ï‡ßã‡¶® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßç‡¶¨‡¶ø‡¶ò‡¶æ‡¶§ ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø? ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶è‡¶á ‡¶Ö‡¶≠‡¶ø‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶ü‡¶ø ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®?",
    "reasoning": "‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ü‡¶ø‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¶‡ßç‡¶¨‡¶ø‡¶ò‡¶æ‡¶§ ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§ ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø ‡¶Ø‡¶æ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡ßá ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ ‡¶Ø‡ßá‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§ ‡¶Ü‡¶Æ‡¶ø ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶ï‡ßá ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶õ‡¶æ‡¶°‡¶º‡¶æ‡¶á ‡¶è‡¶á ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶ö‡¶ø‡¶®‡¶§‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡•§ ‡¶Ø‡¶¶‡¶ø ‡¶§‡¶æ‡¶∞‡¶æ ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶Ø‡ßá ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶â‡¶™‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§, ‡¶§‡¶æ‡¶∞‡¶æ 6 ‡¶è‡¶∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶ï‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶Ø‡¶æ 5 ‡¶è ‡¶Ø‡ßã‡¶ó ‡¶π‡¶Ø‡¶º‡•§"
}
"""

# Step-by-Step Mode - English
STEP_BY_STEP_PROMPT_ENGLISH = """
You are an AI math tutor specializing in high school algebra. Your goal is to help students understand and solve math problems step-by-step. Please remember to answer in English.

**Your Process:**

1. **Problem Reception:** The student will give you an equation or math problem.
2. **Analysis:** Solve the problem one step at a time. Clearly and concisely explain why you are doing each step, emphasizing the underlying mathematical principles.
3. **Check for Understanding:** After each step, ask the student if they understand it.
4. **Provide Feedback:**
   * **If the student understands:** Proceed to the next step.
   * **If the student doesn't understand or asks for a hint:** Provide a clear, concise explanation or a relevant hint.
5. **Final Solution:** Once you reach the final solution, state the answer clearly.

**Important Instructions:**
- Do not solve the entire problem at once. Only answer one step at a time.
- Always ask if the student understands.
- Your response must be in the following JSON format:

```json
{
  "step_explanation": "Explanation of what we're doing in this step",
  "understanding_check": "Did you understand this step?",
  "is_final_step": false,
  "next_hint": "Hint about what we'll do in the next step"
}
```

If this is the final step, set `is_final_step` to `true` and leave `next_hint` empty.

**Example:**

Student: Solve 2x + 3 = 7.
You:
```json
{
  "step_explanation": "First, we will subtract 3 from both sides of the equation to isolate the 'x' term. This gives us 2x = 4.",
  "understanding_check": "Did you understand this step?",
  "is_final_step": false,
  "next_hint": "In the next step, we'll divide both sides by 2 to find the value of x."
}
```

Student: Yes
You:
```json
{
  "step_explanation": "Excellent! Now, we will divide both sides by 2 to find the value of x. This gives us x = 2.",
  "understanding_check": "Do you understand?",
  "is_final_step": true,
  "next_hint": ""
}
```

So let's begin!
"""

# Step-by-Step Mode - Bangla
STEP_BY_STEP_PROMPT_BANGLA = """
‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶è‡¶Ü‡¶á ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï, ‡¶Ø‡¶ø‡¶®‡¶ø ‡¶â‡¶ö‡ßç‡¶ö ‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º‡ßá‡¶∞ ‡¶¨‡ßÄ‡¶ú‡¶ó‡¶£‡¶ø‡¶§ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø ‡¶π‡¶≤ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶ó‡¶æ‡¶£‡¶ø‡¶§‡¶ø‡¶ï ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ ‡¶ï‡¶∞‡¶æ‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶® ‡¶Ø‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§

**‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ:**

1. **‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶ó‡ßç‡¶∞‡¶π‡¶£:** ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£ ‡¶¨‡¶æ ‡¶ó‡¶æ‡¶£‡¶ø‡¶§‡¶ø‡¶ï ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶¶‡ßá‡¶¨‡ßá‡•§
2. **‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£:** ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ü‡¶ø ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™ ‡¶ï‡¶∞‡ßá ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßá‡¶® ‡¶ï‡¶∞‡¶õ‡ßá‡¶® ‡¶§‡¶æ ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶≠‡¶æ‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶Ö‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶®‡¶ø‡¶π‡¶ø‡¶§ ‡¶ó‡¶æ‡¶£‡¶ø‡¶§‡¶ø‡¶ï ‡¶®‡ßÄ‡¶§‡¶ø‡¶ó‡ßÅ‡¶≤‡¶ø‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶ú‡ßã‡¶∞ ‡¶¶‡¶ø‡¶®‡•§
3. **‡¶¨‡ßã‡¶ù‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ:** ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶™‡¶∞‡ßá, ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶è‡¶á ‡¶ß‡¶æ‡¶™‡¶ü‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶§‡¶æ ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§
4. **‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ú‡¶æ‡¶®‡¶æ‡¶®‡ßã:**
   * **‡¶Ø‡¶¶‡¶ø ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá:** ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Ø‡¶æ‡¶®‡•§
   * **‡¶Ø‡¶¶‡¶ø ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶®‡¶æ ‡¶™‡¶æ‡¶∞‡ßá ‡¶¨‡¶æ ‡¶ï‡ßã‡¶®‡ßã ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶ö‡¶æ‡¶Ø‡¶º:** ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü, ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶¨‡¶æ ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶¶‡¶ø‡¶®‡•§
5. **‡¶ö‡ßÇ‡¶°‡¶º‡¶æ‡¶®‡ßç‡¶§ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®:** ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ö‡ßÇ‡¶°‡¶º‡¶æ‡¶®‡ßç‡¶§ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá ‡¶™‡ßå‡¶Å‡¶õ‡ßá ‡¶ó‡ßá‡¶≤‡ßá, ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶≠‡¶æ‡¶¨‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ü‡¶ø ‡¶¨‡¶≤‡ßÅ‡¶®‡•§

**‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ:**
- ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞‡ßá ‡¶™‡ßÅ‡¶∞‡ßã ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§ ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶®‡•§
- ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§
- ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶®‡¶ø‡¶Æ‡ßç‡¶®‡¶≤‡¶ø‡¶ñ‡¶ø‡¶§ JSON ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡ßá ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá:

```json
{
  "step_explanation": "‡¶è‡¶á ‡¶ß‡¶æ‡¶™‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶Ø‡¶æ ‡¶ï‡¶∞‡¶õ‡¶ø ‡¶§‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ",
  "understanding_check": "‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶è‡¶á ‡¶ß‡¶æ‡¶™‡¶ü‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá‡¶®?",
  "is_final_step": false,
  "next_hint": "‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ï‡ßÄ ‡¶ï‡¶∞‡¶¨ ‡¶§‡¶æ‡¶∞ ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§"
}
```

‡¶Ø‡¶¶‡¶ø ‡¶è‡¶ü‡¶ø ‡¶ö‡ßÇ‡¶°‡¶º‡¶æ‡¶®‡ßç‡¶§ ‡¶ß‡¶æ‡¶™ ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá `is_final_step` ‡¶ï‡ßá `true` ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç `next_hint` ‡¶ñ‡¶æ‡¶≤‡¶ø ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®‡•§

**‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:**

‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ: 2x + 3 = 7 ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§
‡¶Ü‡¶™‡¶®‡¶ø:
```json
{
  "step_explanation": "‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá, ‡¶Ü‡¶Æ‡¶∞‡¶æ 'x' ‡¶è‡¶∞ ‡¶™‡¶¶‡¶ü‡¶ø‡¶ï‡ßá ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡¶Æ‡ßÄ‡¶ï‡¶∞‡¶£‡ßá‡¶∞ ‡¶â‡¶≠‡¶Ø‡¶º ‡¶¶‡¶ø‡¶ï ‡¶•‡ßá‡¶ï‡ßá 3 ‡¶¨‡¶ø‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡•§ ‡¶è‡¶§‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶™‡¶æ‡¶á 2x = 4‡•§",
  "understanding_check": "‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶è‡¶á ‡¶ß‡¶æ‡¶™‡¶ü‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá‡¶®?",
  "is_final_step": false,
  "next_hint": "‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ x ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶® ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶â‡¶≠‡¶Ø‡¶º ‡¶™‡¶ï‡ßç‡¶∑‡¶ï‡ßá 2 ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶¨‡•§"
}
```

‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ: ‡¶π‡ßç‡¶Ø‡¶æ‡¶Å
‡¶Ü‡¶™‡¶®‡¶ø:
```json
{
  "step_explanation": "‡¶ö‡¶Æ‡ßé‡¶ï‡¶æ‡¶∞! ‡¶è‡¶ñ‡¶®, ‡¶Ü‡¶Æ‡¶∞‡¶æ x ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶® ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶â‡¶≠‡¶Ø‡¶º ‡¶™‡¶ï‡ßç‡¶∑‡¶ï‡ßá 2 ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶¨‡•§ ‡¶è‡¶§‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶™‡¶æ‡¶á x = 2‡•§",
  "understanding_check": "‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá‡¶®?",
  "is_final_step": true,
  "next_hint": ""
}
```

‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶ï!
"""

# Initialize Langchain components for Adaptive Mode
@st.cache_resource
def setup_adaptive_llm(language):
    # Initialize the base model
    model = ChatGroq(model_name="qwen-qwq-32b", temperature=0.1)
    
    # Select the appropriate system prompt based on language
    if language == "Bangla":
        system_prompt = ADAPTIVE_PROMPT_BANGLA
    else:
        system_prompt = ADAPTIVE_PROMPT_ENGLISH
    
    # Create the prompt template with placeholder for adaptive prompts
    prompt = ChatPromptTemplate.from_messages(
        [
            ('system', "{system_prompt}"),
            MessagesPlaceholder(variable_name="messages")
        ]
    ).partial(system_prompt=system_prompt)
    
    # Create the chain
    chain = prompt | model
    return chain, model, system_prompt

# Initialize Langchain components for Step-by-Step Mode
@st.cache_resource
def setup_step_by_step_llm(language):
    # Initialize the base model
    model = ChatGroq(model_name="qwen-qwq-32b", temperature=0.1)
    
    # Select the appropriate system prompt based on language
    if language == "Bangla":
        system_prompt = STEP_BY_STEP_PROMPT_BANGLA
    else:
        system_prompt = STEP_BY_STEP_PROMPT_ENGLISH
    
    # Create the prompt template
    prompt = ChatPromptTemplate.from_messages(
        [
            ('system', system_prompt),
            MessagesPlaceholder(variable_name="messages")
        ]
    )
    
    # Create the chain
    chain = prompt | model
    return chain, model

# Setup the runnable with message history
@st.cache_resource(show_spinner=False)
def setup_runnable(_chain):
    store = {}
    
    def get_session_history(session_id: str) -> ChatMessageHistory:
        if session_id not in store:
            store[session_id] = ChatMessageHistory()
        return store[session_id]
    
    runnable = RunnableWithMessageHistory(_chain, get_session_history)
    return runnable

# Function to process model output for sentiment analysis (Adaptive Mode)
def process_sentiment_output(output_text):
    try:
        return robust_sentiment_parser.parse(output_text)
    except Exception as e:
        st.sidebar.error(f"Error parsing sentiment: {str(e)}")
        return StuOutputCorrectness(sentiment="partially_correct")

# Function to process model output for adaptive prompt (Adaptive Mode)
def process_adaptive_output(output_text):
    try:
        return robust_adaptive_parser.parse(output_text)
    except Exception as e:
        st.sidebar.error(f"Error parsing adaptive prompt: {str(e)}")
        return AdaptivePrompt(adaptive_prompt="The model output could not be parsed correctly. Please provide a hint for the current step without giving away the solution.")

# Function to process model output for tutor response (Adaptive Mode)
def process_tutor_response_output(output_text):
    try:
        return robust_tutor_response_parser.parse(output_text)
    except Exception as e:
        st.sidebar.error(f"Error parsing tutor response: {str(e)}")
        return TutorResponse(
            hint="I need to provide a hint rather than a complete solution. What specific technique could you apply here?",
            reasoning="The parsing failed, but I should focus on providing guidance without solutions."
        )

# Function to process model output for step solution (Step-by-Step Mode)
def process_step_solution_output(output_text, language):
    try:
        step_solution = robust_step_solution_parser.parse(output_text)
        return step_solution
    except Exception as e:
        st.sidebar.error(f"Error parsing step solution: {str(e)}")
        # Create a default response based on the language
        if language == "Bangla":
            return StepSolution(
                step_explanation="‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶è‡¶á ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶¨‡•§",
                understanding_check="‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶è‡¶á ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá‡¶®?",
                is_final_step=False,
                next_hint="‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ü‡¶ø ‡¶≠‡¶æ‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡¶¨‡•§"
            )
        else:
            return StepSolution(
                step_explanation="I'll help you solve this problem step by step.",
                understanding_check="Do you understand this approach?",
                is_final_step=False,
                next_hint="We'll first try to understand the problem clearly."
            )
def setup_sentiment_analyzer(model):
    # Create prompt template for sentiment analysis
    sentiment_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", 
             """Analyze the following student response to a math problem and classify its correctness.
             Determine whether it is 'correct', 'partially_correct', or 'incorrect'.
             
             Previous tutor hint: {tutor_hint}
             Student Response: {student_response}
             
             IMPORTANT: Your response must be a valid JSON object with the following format:
             {{
                 "sentiment": "correct" OR "partially_correct" OR "incorrect"
             }}
             
             Do not include any explanations, thinking, or additional text outside the JSON object.
             """),
        ]
    )

# Function to enrich input with sentiment analysis (Adaptive Mode)
def create_sentiment_analyzer(sentiment_chain):
    def analyze_sentiment(input_dict: Dict[str, Any]) -> Dict[str, Any]:
        # Extract student response and tutor hint
        student_response = input_dict.get("student_response", "")
        tutor_hint = input_dict.get("tutor_hint", "")
        
        # Only analyze if there's a student response
        if student_response:
            try:
                # Get raw output from the model
                sentiment_output = sentiment_chain.invoke({
                    "student_response": student_response,
                    "tutor_hint": tutor_hint
                })
                
                # Process the output to extract sentiment
                sentiment_result = process_sentiment_output(sentiment_output.content)
                
                return {
                    **input_dict,
                    "sentiment": sentiment_result.sentiment
                }
            except Exception as e:
                st.sidebar.error(f"Sentiment analysis error: {str(e)}")
                return {
                    **input_dict,
                    "sentiment": "unknown"
                }
        else:
            # No student response to analyze yet
            return {
                **input_dict,
                "sentiment": "initial"
            }
    
    return RunnableLambda(analyze_sentiment)

# Function to create the adaptive prompt generator (Adaptive Mode)
def create_adaptive_prompt_generator(model, base_prompt):
    # Setup the prompt generators
    prompt_correct = ChatPromptTemplate.from_messages(
        [
            ("system",
             """
             Your task is to generate one adaptive prompt only. This prompt will be used as the system prompt for the main model.
             Think of yourself as a supervisor providing the best instruction for the AI tutor.
             
             The student gave a CORRECT response: {student_response}
             Previous tutor hint: {tutor_hint}
             
             Generate an adaptive prompt that:
             1. Acknowledges the student's correct understanding
             2. Instructs the tutor to move to the NEXT STEP ONLY (not multiple steps)
             3. Emphasizes that the tutor should provide only a hint for this next step, not a solution
             4. Reminds the tutor to ask a guiding question about this next step
             5. Reinforces that the tutor must NEVER provide complete solutions
             6. Reminds the tutor to structure the response as a JSON with "hint" and "reasoning" fields
             
             IMPORTANT: Your response must be a valid JSON object with the following format:
             {{
                 "adaptive_prompt": "your adaptive prompt text here"
             }}
             
             Do not include any explanations, thinking, or additional text outside the JSON object.
             """)
        ]
    )
    
    prompt_partially_correct = ChatPromptTemplate.from_messages(
        [
            ("system",
             """
             Your task is to generate one adaptive prompt only. This prompt will be used as the system prompt for the main model.
             Think of yourself as a supervisor providing the best instruction for the AI tutor.
             
             The student gave a PARTIALLY CORRECT response: {student_response}
             Previous tutor hint: {tutor_hint}
             
             Generate an adaptive prompt that:
             1. Acknowledges what the student understood correctly
             2. Identifies the specific misconception or error in their understanding
             3. Instructs the tutor to provide a more targeted hint addressing this specific issue
             4. Emphasizes that the tutor should NOT move to the next step yet
             5. Reminds the tutor to ask a more specific guiding question
             6. Reinforces that the tutor must NEVER provide complete solutions
             7. Reminds the tutor to structure the response as a JSON with "hint" and "reasoning" fields
             
             IMPORTANT: Your response must be a valid JSON object with the following format:
             {{
                 "adaptive_prompt": "your adaptive prompt text here"
             }}
             
             Do not include any explanations, thinking, or additional text outside the JSON object.
             """)
        ]
    )
    
    prompt_incorrect = ChatPromptTemplate.from_messages(
        [
            ("system",
             """
             Your task is to generate one adaptive prompt only. This prompt will be used as the system prompt for the main model.
             Think of yourself as a supervisor providing the best instruction for the AI tutor.
             
             The student gave an INCORRECT response: {student_response}
             Previous tutor hint: {tutor_hint}
             
             Generate an adaptive prompt that:
             1. Identifies the fundamental misunderstanding in the student's approach
             2. Instructs the tutor to provide a more basic hint that addresses this misunderstanding
             3. Directs the tutor to break down the current step into smaller sub-steps
             4. Suggests a simpler question to check the student's understanding of prerequisites
             5. Emphasizes that the tutor should NOT move to the next step yet
             6. Reinforces that the tutor must NEVER provide complete solutions, even if the student is struggling
             7. Reminds the tutor to structure the response as a JSON with "hint" and "reasoning" fields
             
             IMPORTANT: Your response must be a valid JSON object with the following format:
             {{
                 "adaptive_prompt": "your adaptive prompt text here"
             }}
             
             Do not include any explanations, thinking, or additional text outside the JSON object.
             """)
        ]
    )
    
    # Create the branch chain with robust parsing
    def generate_adaptive_prompt(input_dict):
        sentiment = input_dict.get("sentiment", "unknown")
        student_response = input_dict.get("student_response", "")
        tutor_hint = input_dict.get("tutor_hint", "")
        
        try:
            if sentiment == "correct":
                output = model.invoke(prompt_correct.format(
                    student_response=student_response,
                    tutor_hint=tutor_hint
                ))
                return process_adaptive_output(output.content)
            
            elif sentiment == "partially_correct":
                output = model.invoke(prompt_partially_correct.format(
                    student_response=student_response,
                    tutor_hint=tutor_hint
                ))
                return process_adaptive_output(output.content)
            
            elif sentiment == "incorrect":
                output = model.invoke(prompt_incorrect.format(
                    student_response=student_response,
                    tutor_hint=tutor_hint
                ))
                return process_adaptive_output(output.content)
            
            else:
                # Default for unknown sentiment
                return AdaptivePrompt(adaptive_prompt=base_prompt)
                
        except Exception as e:
            st.sidebar.error(f"Error generating adaptive prompt: {str(e)}")
            return AdaptivePrompt(adaptive_prompt=base_prompt)
    
    return RunnableLambda(generate_adaptive_prompt)

# Function to enforce hint-only approach in model responses (Adaptive Mode)
def enforce_hint_only_approach(response):
    # Check if the response is already a TutorResponse object
    if isinstance(response, TutorResponse):
        # Check if the hint appears to be giving a complete solution
        hint_text = response.hint.lower()
        solution_indicators = [
            "the solution is",
            "the answer is",
            "solving this completely",
            "to solve this problem",
            "we get",
            "therefore, x =",
            "therefore x =",
            "thus, x =",
            "thus x =",
            "x equals",
            "x is equal to"
        ]
        
        # If the hint contains solution indicators, replace it with a more appropriate hint
        for indicator in solution_indicators:
            if indicator in hint_text:
                return TutorResponse(
                    hint="I need to provide a hint rather than a complete solution. Let me give you a small hint for the next step: What specific technique could you apply here? Try to think about what we're trying to accomplish in this particular step. Can you attempt this step and share your thinking?",
                    reasoning="I detected that my response might be giving away too much of the solution. I should focus on providing guidance without solutions."
                )
        
        # If no solution indicators found, return the original response
        return response
    else:
        # If it's a string (from older versions), convert it to a TutorResponse
        try:
            if isinstance(response, str):
                return TutorResponse(
                    hint=response,
                    reasoning="This response was processed from a string format. I'm focusing on providing guidance without solutions."
                )
            else:
                # For any other type, return a default TutorResponse
                return TutorResponse(
                    hint="Let me give you a hint for this step. What approach do you think would be most appropriate here?",
                    reasoning="I'm providing a generic hint since the response format was unexpected."
                )
        except Exception as e:
            # If any error occurs, return a safe default
            return TutorResponse(
                hint="I need to provide a hint rather than a complete solution. What specific technique could you apply here?",
                reasoning="There was an error processing the response, but I should focus on providing guidance without solutions."
            )

# Main Streamlit UI
def main():
    st.title("Math Tutor")
    
    # Sidebar configuration
    st.sidebar.title("Settings")
    
    # Mode selection
    mode = st.sidebar.radio(
        "Select Mode / ‡¶Æ‡ßã‡¶° ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®",
        ["Interactive (Adaptive) / ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ (‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶ø‡¶§)", "Step-by-Step / ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá"]
    )
    
    # Language selection
    language = st.sidebar.selectbox(
        "Select Language / ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®", 
        ["English", "Bangla"]
    )
    
    # Display appropriate header based on mode and language
    if mode == "Interactive (Adaptive) / ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ (‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶ø‡¶§)":
        if language == "Bangla":
            st.header("‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï")
            st.markdown("‡¶è‡¶á ‡¶ü‡ßÅ‡¶≤‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶¨‡ßá‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø ‡¶ï‡¶∞‡ßá, ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¨‡ßã‡¶ù‡¶æ‡¶∞ ‡¶∏‡ßç‡¶§‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶Æ‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶®‡ßá‡¶¨‡ßá‡•§")
        else:
            st.header("Interactive Math Tutor")
            st.markdown("This tool will help you solve math problems through hints and guiding questions. Based on your responses, the tutor will adapt to your level of understanding.")
    else:
        if language == "Bangla":
            st.header("‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡¶ï‡¶æ‡¶∞‡ßÄ")
            st.markdown("‡¶è‡¶á ‡¶ü‡ßÅ‡¶≤‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶¨‡ßá‡•§ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶™‡¶∞‡ßá, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá‡¶® ‡¶ï‡¶ø‡¶®‡¶æ ‡¶§‡¶æ ‡¶ú‡¶æ‡¶®‡¶æ‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§")
        else:
            st.header("Step-by-Step Math Problem Solver")
            st.markdown("This tool will help you solve math problems step by step. After each step, you'll need to indicate whether you understand.")
    
    # Initialize session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "adaptive_prompt" not in st.session_state:
        st.session_state.adaptive_prompt = ""
    
    if "sentiment" not in st.session_state:
        st.session_state.sentiment = "initial"
    
    if "last_tutor_hint" not in st.session_state:
        st.session_state.last_tutor_hint = ""
    
    if "consecutive_incorrect" not in st.session_state:
        st.session_state.consecutive_incorrect = 0
    
    if "current_step" not in st.session_state:
        st.session_state.current_step = 0
    
    if "problem_solved" not in st.session_state:
        st.session_state.problem_solved = False
    
    if "current_mode" not in st.session_state:
        st.session_state.current_mode = mode
    
    if "current_language" not in st.session_state:
        st.session_state.current_language = language
    
    # Check if mode or language has changed
    if st.session_state.current_mode != mode or st.session_state.current_language != language:
        st.session_state.messages = []
        st.session_state.adaptive_prompt = ""
        st.session_state.sentiment = "initial"
        st.session_state.last_tutor_hint = ""
        st.session_state.consecutive_incorrect = 0
        st.session_state.current_step = 0
        st.session_state.problem_solved = False
        st.session_state.current_mode = mode
        st.session_state.current_language = language
    
    # Setup sidebar for Adaptive Mode
    if mode == "Interactive (Adaptive) / ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ (‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶ø‡¶§)":
        st.sidebar.title("Analysis Information")
        st.sidebar.subheader("Student Response Analysis")
        sentiment_display = st.sidebar.empty()
        
        st.sidebar.subheader("Adaptive Prompt")
        adaptive_prompt_display = st.sidebar.empty()
        
        st.sidebar.subheader("Hint Level")
        hint_level_display = st.sidebar.empty()
    
    # Display existing messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if mode == "Interactive (Adaptive) / ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ (‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶ø‡¶§)":
                # For adaptive mode
                if message["role"] == "assistant" and "hint" in message and "reasoning" in message:
                    st.markdown(message["hint"])
                    with st.expander("See tutor's reasoning / ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï‡ßá‡¶∞ ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®"):
                        st.markdown(message["reasoning"])
                else:
                    st.markdown(message["content"])
            else:
                # For step-by-step mode
                if message["role"] == "assistant" and "step_data" in message:
                    step_data = message["step_data"]
                    
                    # Display the step explanation
                    st.markdown(step_data["step_explanation"])
                    
                    # Display the understanding check
                    st.markdown(f"**{step_data['understanding_check']}**")
                    
                    # If it's the final step, add a visual indicator
                    if step_data["is_final_step"]:
                        if language == "Bangla":
                            st.success("‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá! ‚úÖ")
                        else:
                            st.success("Solution completed! ‚úÖ")
                else:
                    st.markdown(message["content"])
    
    # Get user input
    if language == "Bangla":
        prompt_text = "‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ó‡¶£‡¶ø‡¶§ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶®..."
    else:
        prompt_text = "Enter your math problem here..."
    
    if prompt := st.chat_input(prompt_text):
        # Add user message to session state
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        try:
            # Handle based on selected mode
            if mode == "Interactive (Adaptive) / ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ (‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶ø‡¶§)":
                # Adaptive Mode
                # Initialize LLM components
                chain, model, base_prompt = setup_adaptive_llm(language)
                sentiment_chain = setup_sentiment_analyzer(model)
                sentiment_analyzer = create_sentiment_analyzer(sentiment_chain)
                adaptive_prompt_generator = create_adaptive_prompt_generator(model, base_prompt)
                runnable = setup_runnable(chain)
                
                # Determine if this is the first message or a response to a hint
                is_first_message = len([m for m in st.session_state.messages if m["role"] == "assistant"]) == 0
                
                if is_first_message:
                    # First message is a math problem, no sentiment analysis needed
                    current_system_prompt = base_prompt
                    st.session_state.sentiment = "initial"
                    if language == "Bangla":
                        sentiment_display.info("‡¶™‡ßç‡¶∞‡¶æ‡¶•‡¶Æ‡¶ø‡¶ï ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶ú‡¶Æ‡¶æ")
                        adaptive_prompt_display.info("‡¶Æ‡ßÇ‡¶≤ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡ßá")
                        hint_level_display.info("‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶æ‡¶∞‡ßç‡¶° ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶∏‡ßç‡¶§‡¶∞")
                    else:
                        sentiment_display.info("Initial problem submission")
                        adaptive_prompt_display.info("Using base tutor prompt")
                        hint_level_display.info("Standard hint level")
                    st.session_state.consecutive_incorrect = 0
                else:
                    # Analyze the student's response to the previous hint
                    analysis_input = {
                        "student_response": prompt,
                        "tutor_hint": st.session_state.last_tutor_hint
                    }
                    
                    # Run sentiment analysis
                    analysis_result = sentiment_analyzer.invoke(analysis_input)
                    st.session_state.sentiment = analysis_result.get("sentiment", "unknown")
                    
                    # Update consecutive incorrect counter
                    if st.session_state.sentiment == "incorrect":
                        st.session_state.consecutive_incorrect += 1
                    else:
                        st.session_state.consecutive_incorrect = 0
                    
                    # Display sentiment in sidebar
                    sentiment_emoji = {
                        "correct": "‚úÖ",
                        "partially_correct": "‚ö†Ô∏è",
                        "incorrect": "‚ùå",
                        "unknown": "‚ùì",
                        "initial": "üîç"
                    }
                    
                    if language == "Bangla":
                        sentiment_labels = {
                            "correct": "‡¶∏‡¶†‡¶ø‡¶ï",
                            "partially_correct": "‡¶Ü‡¶Ç‡¶∂‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶†‡¶ø‡¶ï",
                            "incorrect": "‡¶≠‡ßÅ‡¶≤",
                            "unknown": "‡¶Ö‡¶ú‡¶æ‡¶®‡¶æ",
                            "initial": "‡¶™‡ßç‡¶∞‡¶æ‡¶•‡¶Æ‡¶ø‡¶ï"
                        }
                        sentiment_display.info(f"{sentiment_emoji.get(st.session_state.sentiment, '‚ùì')} ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ‡¶¨‡¶¶‡ßç‡¶ß ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá: {sentiment_labels.get(st.session_state.sentiment, '‡¶Ö‡¶ú‡¶æ‡¶®‡¶æ')}")
                    else:
                        sentiment_display.info(f"{sentiment_emoji.get(st.session_state.sentiment, '‚ùì')} Response classified as: {st.session_state.sentiment.replace('_', ' ').title()}")
                    
                    # Generate adaptive prompt based on sentiment
                    adaptive_result = adaptive_prompt_generator.invoke(analysis_result)
                    
                    # Enhance adaptive prompt based on consecutive incorrect responses
                    if st.session_state.consecutive_incorrect >= 2:
                        if language == "Bangla":
                            hint_level = f"‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶∏‡ßç‡¶§‡¶∞ ({st.session_state.consecutive_incorrect} ‡¶ï‡ßç‡¶∞‡¶Æ‡¶æ‡¶ó‡¶§ ‡¶≠‡ßÅ‡¶≤ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ)"
                            hint_level_display.warning(hint_level)
                            
                            # Add additional guidance for multiple incorrect responses
                            additional_guidance = f"""
                            ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£: ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ {st.session_state.consecutive_incorrect}‡¶ü‡¶ø ‡¶ï‡ßç‡¶∞‡¶Æ‡¶æ‡¶ó‡¶§ ‡¶≠‡ßÅ‡¶≤ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§
                            
                            ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶£‡ßÄ‡¶Ø‡¶º:
                            1. ‡¶Ü‡¶∞‡¶ì ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶¶‡¶ø‡¶®, ‡¶§‡¶¨‡ßá ‡¶è‡¶ñ‡¶®‡¶ì ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶®‡¶Ø‡¶º
                            2. ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶ß‡¶æ‡¶™‡¶ü‡¶ø‡¶ï‡ßá ‡¶Ü‡¶∞‡¶ì ‡¶õ‡ßã‡¶ü, ‡¶Ü‡¶∞‡¶ì ‡¶∏‡¶π‡¶ú‡ßá ‡¶™‡¶∞‡¶ø‡¶ö‡¶æ‡¶≤‡¶®‡¶æ‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶â‡¶™-‡¶ß‡¶æ‡¶™‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
                            3. ‡¶¨‡¶ø‡¶¨‡ßá‡¶ö‡¶®‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶∞ ‡¶ï‡ßã‡¶®‡ßã ‡¶™‡ßÇ‡¶∞‡ßç‡¶¨‡¶∂‡¶∞‡ßç‡¶§ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶∏‡ßç‡¶•‡¶ø‡¶§ ‡¶•‡¶æ‡¶ï‡ßá
                            4. ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï ‡¶¨‡ßã‡¶ù‡¶æ‡¶™‡¶°‡¶º‡¶æ ‡¶™‡¶∞‡ßÄ‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ñ‡ßÅ‡¶¨ ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
                            5. ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶¨‡¶æ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶∂‡ßà‡¶≤‡ßÄ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
                            
                            ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶®: ‡¶è‡¶Æ‡¶®‡¶ï‡¶ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶∞‡¶§ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ‡¶∞‡ßç‡¶•‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá‡¶ì, ‡¶ï‡¶ñ‡¶®‡¶á ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§
                            ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ "hint" ‡¶è‡¶¨‡¶Ç "reasoning" ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞ ‡¶∏‡¶π ‡¶è‡¶ï‡¶ü‡¶ø JSON ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá ‡¶ï‡¶æ‡¶†‡¶æ‡¶Æ‡ßã‡¶¨‡¶¶‡ßç‡¶ß ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§
                            """
                        else:
                            hint_level = f"Enhanced hint level ({st.session_state.consecutive_incorrect} consecutive incorrect responses)"
                            hint_level_display.warning(hint_level)
                            
                            # Add additional guidance for multiple incorrect responses
                            additional_guidance = f"""
                            IMPORTANT: The student has given {st.session_state.consecutive_incorrect} consecutive incorrect responses.
                            
                            You should:
                            1. Provide a more explicit hint, but still not a complete solution
                            2. Break down the current step into smaller, more manageable sub-steps
                            3. Consider if there's a prerequisite concept the student is missing
                            4. Ask a very basic question to check fundamental understanding
                            5. Use a different approach or explanation style
                            
                            Remember: Even with struggling students, never provide the complete solution.
                            Make sure to structure your response as a JSON with "hint" and "reasoning" fields.
                            """
                        
                        adaptive_result.adaptive_prompt += additional_guidance
                    else:
                        if language == "Bangla":
                            hint_level_display.info("‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶æ‡¶∞‡ßç‡¶° ‡¶á‡¶ô‡ßç‡¶ó‡¶ø‡¶§ ‡¶∏‡ßç‡¶§‡¶∞")
                        else:
                            hint_level_display.info("Standard hint level")
                    
                    st.session_state.adaptive_prompt = adaptive_result.adaptive_prompt
                    
                    # Display adaptive prompt in sidebar
                    if language == "Bangla":
                        adaptive_prompt_display.info(f"‡¶â‡ßé‡¶™‡¶®‡ßç‡¶® ‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü:\n\n{st.session_state.adaptive_prompt[:300]}...")
                    else:
                        adaptive_prompt_display.info(f"Generated adaptive prompt:\n\n{st.session_state.adaptive_prompt[:300]}...")
                    
                    # Combine base prompt with adaptive prompt
                    current_system_prompt = f"{base_prompt}\n\n{st.session_state.adaptive_prompt}"
                
                # Create a dynamic prompt template with the current system prompt
                dynamic_prompt = ChatPromptTemplate.from_messages(
                    [
                        ('system', current_system_prompt),
                        MessagesPlaceholder(variable_name="messages")
                    ]
                )
                
                # Create a new chain with the updated prompt
                dynamic_chain = dynamic_prompt | model
                dynamic_runnable = setup_runnable(dynamic_chain)
                
                # Invoke the chain with the updated prompt
                ai_message = dynamic_runnable.invoke(
                    [HumanMessage(content=prompt)],
                    config={"configurable": {"session_id": 'math_session'}}
                )
                
                # Process the response to extract hint and reasoning
                tutor_response = process_tutor_response_output(ai_message.content)
                
                # Enforce hint-only approach by checking and modifying the response if needed
                tutor_response = enforce_hint_only_approach(tutor_response)
                
                # Save the tutor's hint for next round of analysis
                st.session_state.last_tutor_hint = tutor_response.hint
                
                # Add AI message to session state with structured format
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": tutor_response.hint,  # For backward compatibility
                    "hint": tutor_response.hint,
                    "reasoning": tutor_response.reasoning
                })
                
                # Display the message with expandable reasoning
                with st.chat_message("assistant"):
                    # Display the hint with streaming effect
                    response = tutor_response.hint
                    
                    def stream_data():
                        for word in response.split(" "):
                            yield word + " "
                            time.sleep(0.015)
                    
                    st.write_stream(stream_data)
                    
                    # Display the reasoning in an expander
                    if language == "Bangla":
                        with st.expander("‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ï‡ßá‡¶∞ ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®"):
                            st.markdown(tutor_response.reasoning)
                    else:
                        with st.expander("See tutor's reasoning"):
                            st.markdown(tutor_response.reasoning)
            
            else:
                # Step-by-Step Mode
                # Initialize LLM components
                chain, model = setup_step_by_step_llm(language)
                runnable = setup_runnable(chain)
                
                # Invoke the chain with the updated prompt
                ai_message = runnable.invoke(
                    [HumanMessage(content=prompt)],
                    config={"configurable": {"session_id": 'math_session'}}
                )
                
                # Process the response to extract structured data
                step_solution = process_step_solution_output(ai_message.content, language)
                
                # Add AI message to session state with structured format
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": ai_message.content,  # For backward compatibility
                    "step_data": {
                        "step_explanation": step_solution.step_explanation,
                        "understanding_check": step_solution.understanding_check,
                        "is_final_step": step_solution.is_final_step,
                        "next_hint": step_solution.next_hint
                    }
                })
                
                # Display the message with streaming effect
                with st.chat_message("assistant"):
                    # Display the step explanation with streaming effect
                    response = step_solution.step_explanation
                    
                    def stream_data():
                        for word in response.split(" "):
                            yield word + " "
                            time.sleep(0.015)
                    
                    st.write_stream(stream_data)
                    
                    # Display the understanding check
                    st.markdown(f"**{step_solution.understanding_check}**")
                    
                    # If it's the final step, add a visual indicator
                    if step_solution.is_final_step:
                        if language == "Bangla":
                            st.success("‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá! ‚úÖ")
                        else:
                            st.success("Solution completed! ‚úÖ")
                
                # Update the current step
                st.session_state.current_step += 1
                
                # Update problem solved status
                if step_solution.is_final_step:
                    st.session_state.problem_solved = True
                
        except Exception as e:
            if language == "Bangla":
                st.error(f"‡¶è‡¶ï‡¶ü‡¶ø ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶ò‡¶ü‡ßá‡¶õ‡ßá: {e}")
                st.error("‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ Groq API ‡¶ï‡ßÄ ‡¶è‡¶¨‡¶Ç ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶®‡ßá‡¶ü ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó ‡¶™‡¶∞‡ßÄ‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§")
            else:
                st.error(f"An error occurred: {e}")
                st.error("Please check your Groq API key and internet connection.")
            st.stop()
    
    # Add a reset button
    st.sidebar.divider()
    if language == "Bangla":
        reset_text = "‡¶∞‡¶ø‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®"
    else:
        reset_text = "Reset"
        
    if st.sidebar.button(reset_text):
        st.session_state.messages = []
        st.session_state.adaptive_prompt = ""
        st.session_state.sentiment = "initial"
        st.session_state.last_tutor_hint = ""
        st.session_state.consecutive_incorrect = 0
        st.session_state.current_step = 0
        st.session_state.problem_solved = False
        st.rerun()

if __name__ == "__main__":
    main()
